{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "import scipy, sklearn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading signals from .wav files\n",
    "blues = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/blues/*.wav')]\n",
    "classical = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/classical/*.wav')]\n",
    "country = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/country/*.wav')]\n",
    "disco = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/disco/*.wav')]\n",
    "hiphop = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/hiphop/*.wav')]\n",
    "jazz = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/jazz/*.wav')]\n",
    "metal = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/metal/*.wav')]\n",
    "pop = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/pop/*.wav')]\n",
    "reggae = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/reggae/*.wav')]\n",
    "rock = [librosa.load(p)[0] for p in Path().glob('data_gtzan/genres_original/rock/*.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for extracting all features\n",
    "def extract_features(signal, derivative=0, sr=22050, n_fft=2048, hop_length=512):\n",
    "    #STFT of signal\n",
    "    S, phase = librosa.magphase(librosa.stft(y=signal, n_fft=n_fft, hop_length=hop_length))\n",
    "    \n",
    "    features = {'centroid': librosa.feature.spectral_centroid(S=S, sr=sr).ravel(),\n",
    "                'bandwidth': librosa.feature.spectral_bandwidth(S=S, sr=sr).ravel(),\n",
    "                'contrast': librosa.feature.spectral_contrast(S=S, sr=sr).ravel(),\n",
    "                'flatness': librosa.feature.spectral_flatness(S=S, power=2).ravel(),\n",
    "                'rolloff': librosa.feature.spectral_rolloff(S=S, sr=sr).ravel(),\n",
    "                'zcr': librosa.feature.zero_crossing_rate(signal, frame_length=n_fft, hop_length=hop_length).ravel(),\n",
    "                'rmse': librosa.feature.rms(S=S).ravel(),}\n",
    "    \n",
    "    #pre-computed power spectrogram and mfcc\n",
    "    D = np.abs(S)**2\n",
    "    melspec = librosa.feature.melspectrogram(S=D, sr=sr, n_fft=n_fft, hop_length=hop_length)\n",
    "    mfcc = librosa.feature.mfcc(S=librosa.power_to_db(melspec), sr=sr, n_mfcc=13)\n",
    "    \n",
    "    for index, value in enumerate(mfcc):\n",
    "        features['mfcc_{}'.format(index)] = value.ravel()\n",
    "        \n",
    "    chroma_cqt = librosa.feature.chroma_cqt(signal, sr=sr, hop_length=hop_length)\n",
    "    for index,value in enumerate(chroma_cqt):\n",
    "        features['chroma_cqt_{}'.format(index)] = value.ravel()\n",
    "    \n",
    "    #Poly features\n",
    "    p0 = librosa.feature.poly_features(S=S, order=0)\n",
    "    p1 = librosa.feature.poly_features(S=S, order=1)\n",
    "    p2 = librosa.feature.poly_features(S=S, order=2)\n",
    "    features['poly_features_0_0'] = p0[0].ravel()\n",
    "    features['poly_features_1_0'] = p1[0].ravel()\n",
    "    features['poly_features_1_1'] = p1[1].ravel()\n",
    "    features['poly_features_2_0'] = p2[0].ravel()\n",
    "    features['poly_features_2_1'] = p2[1].ravel()\n",
    "    features['poly_features_2_2'] = p2[2].ravel() \n",
    "    \n",
    "    if(derivative != 0):\n",
    "        for key, value in features.items():\n",
    "            features[key] = librosa.feature.delta(value, order=derivative)\n",
    "   \n",
    "        \n",
    "    def get_feature_stats(features):\n",
    "        result = {}\n",
    "        for k, v in features.items():\n",
    "            result['{}_mean'.format(k)] = np.mean(v)\n",
    "            result['{}_std'.format(k)] = np.std(v)\n",
    "            result['{}_kurtosis'.format(k)] = kurtosis(v)\n",
    "            result['{}_skew'.format(k)] = skew(v)\n",
    "            result['{}_median'.format(k)] = np.median(v)\n",
    "            result['{}_min'.format(k)] = np.min(v)\n",
    "            result['{}_max'.format(k)] = np.max(v)\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    return get_feature_stats(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:41<00:00,  1.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:53<00:00,  1.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:52<00:00,  1.12s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:52<00:00,  1.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:20<00:00,  1.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:17<00:00,  1.37s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:15<00:00,  1.36s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:15<00:00,  1.36s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:15<00:00,  1.36s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:18<00:00,  1.38s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:18<00:00,  1.38s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:20<00:00,  1.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:18<00:00,  1.38s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:19<00:00,  1.39s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:21<00:00,  1.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:25<00:00,  1.46s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:05<00:00,  1.26s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:16<00:00,  1.36s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:01<00:00,  1.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:57<00:00,  1.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:02<00:00,  1.23s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:03<00:00,  1.24s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:00<00:00,  1.20s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:01<00:00,  1.22s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:59<00:00,  1.20s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:02<00:00,  1.23s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:01<00:00,  1.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [01:58<00:00,  1.18s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [02:04<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "#Assiging feature stats to variables\n",
    "#Features without derivative\n",
    "features = {'blues_features': ([extract_features(x) for x in tqdm(blues)]),\n",
    "    'classical_features': ([extract_features(x) for x in tqdm(classical)]),\n",
    "    'country_features': ([extract_features(x) for x in tqdm(country)]),\n",
    "    'disco_features': ([extract_features(x) for x in tqdm(disco)]),\n",
    "    'hiphop_features': ([extract_features(x) for x in tqdm(hiphop)]),           \n",
    "    'jazz_features': ([extract_features(x) for x in tqdm(jazz)]),\n",
    "    'metal_features': ([extract_features(x) for x in tqdm(metal)]),\n",
    "    'pop_features': ([extract_features(x) for x in tqdm(pop)]),\n",
    "    'reggae_features': ([extract_features(x) for x in tqdm(reggae)]),\n",
    "    'rock_features': ([extract_features(x) for x in tqdm(rock)]),}\n",
    "\n",
    "\n",
    "#Features with derivative 1\n",
    "features_delta1 = {'blues_features': ([extract_features(x, derivative=1) for x in tqdm(blues)]),\n",
    "    'classical_features': ([extract_features(x, derivative=1) for x in tqdm(classical)]),\n",
    "    'country_features': ([extract_features(x, derivative=1) for x in tqdm(country)]),\n",
    "    'disco_features': ([extract_features(x, derivative=1) for x in tqdm(disco)]),\n",
    "    'hiphop_features': ([extract_features(x, derivative=1) for x in tqdm(hiphop)]),\n",
    "    'jazz_features': ([extract_features(x, derivative=1) for x in tqdm(jazz)]),\n",
    "    'metal_features': ([extract_features(x, derivative=1) for x in tqdm(metal)]),\n",
    "    'pop_features': ([extract_features(x, derivative=1) for x in tqdm(pop)]),\n",
    "    'reggae_features': ([extract_features(x, derivative=1) for x in tqdm(reggae)]),\n",
    "    'rock_features': ([extract_features(x, derivative=1) for x in tqdm(rock)]),}\n",
    "\n",
    "#Featurest with derivative 2\n",
    "features_delta2 = {'blues_features': ([extract_features(x, derivative=2) for x in tqdm(blues)]),\n",
    "    'classical_features': ([extract_features(x, derivative=2) for x in tqdm(classical)]),\n",
    "    'country_features': ([extract_features(x, derivative=2) for x in tqdm(country)]),\n",
    "    'disco_features': ([extract_features(x, derivative=2) for x in tqdm(disco)]),\n",
    "    'hiphop_features': ([extract_features(x, derivative=2) for x in tqdm(hiphop)]),\n",
    "    'jazz_features': ([extract_features(x, derivative=2) for x in tqdm(jazz)]),\n",
    "    'metal_features': ([extract_features(x, derivative=2) for x in tqdm(metal)]),\n",
    "    'pop_features': ([extract_features(x, derivative=2) for x in tqdm(pop)]),\n",
    "    'reggae_features': ([extract_features(x, derivative=2) for x in tqdm(reggae)]),\n",
    "    'rock_features': ([extract_features(x, derivative=2) for x in tqdm(rock)]),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating features in dataframes\n",
    "#Features without derivatives\n",
    "features_df = pd.DataFrame()\n",
    "for genre in genres:\n",
    "    tmp_df = pd.DataFrame.from_dict(features['{}_features'.format(genre)])\n",
    "    features_df = pd.concat([features_df, tmp_df])    \n",
    "\n",
    "features_df.to_csv('outputs/features.csv',index=False)\n",
    "\n",
    "#Derivative 1 \n",
    "features_df_delta1= pd.DataFrame()\n",
    "for genre in genres:\n",
    "    tmp_df = pd.DataFrame.from_dict(features_delta1['{}_features'.format(genre)])\n",
    "    features_df_delta1 = pd.concat([features_df_delta1, tmp_df])\n",
    "\n",
    "features_df_delta1 = features_df_delta1.add_suffix('_d1') #Adding suffix to features with delta2\n",
    "features_df_delta1.to_csv('outputs/features_delta1.csv',index=False)\n",
    "\n",
    "#Derivative 2\n",
    "features_df_delta2= pd.DataFrame()\n",
    "for genre in genres:\n",
    "    tmp_df = pd.DataFrame.from_dict(features_delta2['{}_features'.format(genre)])\n",
    "    features_df_delta2 = pd.concat([features_df_delta2, tmp_df])\n",
    "\n",
    "features_df_delta2 = features_df_delta2.add_suffix('_d2') #Adding suffix to features with delta2\n",
    "features_df_delta2.to_csv('outputs/features_delta2.csv',index=False)\n",
    "\n",
    "#turevsiz ve 1. turevli featurelari iceren dataframe\n",
    "features_wd1 = pd.concat([features_df, features_df_delta1], axis=1)\n",
    "features_wd1.to_csv('outputs/features_wd1.csv',index=False)\n",
    "#turevsiz, 1. turevli ve 2.turevli featurelari iceren dataframe\n",
    "features_wd1n2 = pd.concat([features_wd1, features_df_delta2], axis=1)\n",
    "features_wd1n2.to_csv('outputs/features_wd1n2.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling all values for machine learning algorithm\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "scaled_features = pd.DataFrame(scaler.fit_transform(features_df.values), columns=features_df.columns)\n",
    "scaled_features_wd1 = pd.DataFrame(scaler.fit_transform(features_wd1.values), columns=features_wd1.columns)\n",
    "scaled_features_wd1n2 = pd.DataFrame(scaler.fit_transform(features_wd1n2.values), columns=features_wd1n2.columns)\n",
    "\n",
    "# Adding labels to audio features for clustering\n",
    "labels_list = [index for index, genre in enumerate(genres) for i in range(len(blues))]\n",
    "scaled_features['label'] = labels_list\n",
    "scaled_features_wd1['label'] = labels_list\n",
    "scaled_features_wd1n2['label'] = labels_list\n",
    "\n",
    "scaled_features.to_csv('outputs/scaled_features.csv',index=False)\n",
    "scaled_features_wd1.to_csv('outputs/scaled_features_wd1.csv',index=False)\n",
    "scaled_features_wd1n2.to_csv('outputs/scaled_features_wd1n2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
